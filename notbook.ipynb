{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    print(f'Batch size: {images.size(0)}') \n",
    "    break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(),\n",
    " transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data/raw\", download=True, train=True, transform=tf),\n",
    "batch_size=64, shuffle=True)\n",
    "test_load = torch.utils.data.DataLoader(datasets.MNIST(\"./data/raw\", download=True, train=False, transform=tf),\n",
    "batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Début du code\n",
    "batch = next(iter(train_loader))\n",
    "x = batch[0][:5]\n",
    "y = batch[1][:5]\n",
    "\n",
    "# Configuration pour les images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "# Boucle pour afficher chaque image\n",
    "for i in range(5):\n",
    "    image = x[i].numpy().squeeze()  \n",
    "    label = y[i].item()\n",
    "\n",
    "    axes[i].imshow(image, cmap='gray') \n",
    "    axes[i].set_title(f'{label}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=96, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, n_kernels, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Définition de l'architecture du réseau\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=n_kernels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=n_kernels, out_channels=n_kernels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(in_features=n_kernels * 4 * 4, out_features=50),\n",
    "\n",
    "            nn.Linear(in_features=50, out_features=output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "n_kernels = 6\n",
    "input_size = 28 * 28\n",
    "output_size = 10 \n",
    "\n",
    "model = ConvNet(input_size=input_size, n_kernels=n_kernels, output_size=output_size)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 107/938 [00:01<00:13, 62.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Step=100: Loss=1.3073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 213/938 [00:03<00:10, 70.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Step=200: Loss=0.3395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 309/938 [00:04<00:08, 70.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Step=300: Loss=0.2505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 414/938 [00:06<00:07, 74.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Step=400: Loss=0.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 511/938 [00:07<00:06, 69.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Step=500: Loss=0.1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 610/938 [00:08<00:04, 70.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Step=600: Loss=0.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 708/938 [00:10<00:03, 64.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Step=700: Loss=0.1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 811/938 [00:11<00:01, 70.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Step=800: Loss=0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 908/938 [00:13<00:00, 72.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Step=900: Loss=0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:13<00:00, 69.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fonction Train\n",
    "\n",
    "def train(model, train_loader, device, n_epoch=1, perm=torch.arange(0, 784).long()):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        running_loss = 0.0\n",
    "        for i, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "\n",
    "            data = data.view(-1, 28*28) \n",
    "            data = data[:, perm] \n",
    "            data = data.view(-1, 1, 28, 28) \n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            logits = model(data) \n",
    "            loss = F.cross_entropy(logits, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99: \n",
    "                print(f'Epoch={epoch}, Step={i+1}: Loss={running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "model = ConvNet(input_size=28*28, n_kernels=6, output_size=10)\n",
    "model.to(device) # TO GPU\n",
    "\n",
    "train(model, train_loader, device, n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.3162, Accuracy: 6.2096\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader, device, perm=torch.arange(0, 784).long()):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device) \n",
    "\n",
    "            # Appliquer les permutations de pixels par la matrice circulaire de Toeplitz\n",
    "            data = data.view(-1, 28*28)\n",
    "            data = data[:, perm]\n",
    "            data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "            logits = model(data)  # Prédiction par le modèle\n",
    "            test_loss += F.cross_entropy(logits, target, reduction='sum').item()\n",
    "            pred = logits.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            #correct += pred.eq(target.view_as(pred)).sum().item() \n",
    "            correct += (pred == target).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)  # Calculer la perte moyenne\n",
    "    accuracy = correct / len(test_loader.dataset)  # Calculer l'accuracy\n",
    "\n",
    "    print(f'Test loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    return test_loss, accuracy\n",
    "\n",
    "model = ConvNet(input_size=28*28, n_kernels=6, output_size=10)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = test(model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
