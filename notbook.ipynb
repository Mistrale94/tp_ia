{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:01:54.302137Z",
     "start_time": "2024-06-24T12:01:09.780008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    print(f'Batch size: {images.size(0)}') \n",
    "    break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:25:22.262161Z",
     "start_time": "2024-06-24T12:25:22.256436Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:01:57.038404Z",
     "start_time": "2024-06-24T12:01:57.033150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:01:58.747206Z",
     "start_time": "2024-06-24T12:01:58.743783Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(),\n",
    " transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:02:54.008116Z",
     "start_time": "2024-06-24T12:02:03.568272Z"
    }
   },
   "outputs": [],
   "source": [
    "#3\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data/raw\", download=True, train=True, transform=tf),\n",
    "batch_size=64, shuffle=True)\n",
    "test_load = torch.utils.data.DataLoader(datasets.MNIST(\"./data/raw\", download=True, train=False, transform=tf),\n",
    "batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:03:31.597072Z",
     "start_time": "2024-06-24T12:03:31.305918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Début du code\n",
    "batch = next(iter(train_loader))\n",
    "x = batch[0][:5]\n",
    "y = batch[1][:5]\n",
    "\n",
    "# Configuration pour les images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "# Boucle pour afficher chaque image\n",
    "for i in range(5):\n",
    "    image = x[i].numpy().squeeze()  \n",
    "    label = y[i].item()\n",
    "\n",
    "    axes[i].imshow(image, cmap='gray') \n",
    "    axes[i].set_title(f'{label}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:29:55.823768Z",
     "start_time": "2024-06-24T12:29:55.798705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=96, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, n_kernels, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Définition de l'architecture du réseau\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=n_kernels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=n_kernels, out_channels=n_kernels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=n_kernels * 4 * 4, out_features=50),\n",
    "            nn.Linear(50, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "n_kernels = 6\n",
    "input_size = 28 * 28\n",
    "output_size = 10 \n",
    "\n",
    "model = ConvNet(input_size=input_size, n_kernels=n_kernels, output_size=output_size)\n",
    "model.to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:29:56.680321Z",
     "start_time": "2024-06-24T12:29:56.676740Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, n_epoch=1, perm=torch.arange(0, 784).long()):\n",
    "    model.train()    \n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            # send to device\n",
    "            data, targets = data.to(device), target.to(device)\n",
    "\n",
    "            # permute pixels\n",
    "            data = data.view(-1, 28*28)\n",
    "            data = data[:, perm]\n",
    "            data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "            # step\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(data)\n",
    "            \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"epoch={epoch}, step={i}: train loss={loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:29:57.141153Z",
     "start_time": "2024-06-24T12:29:57.137503Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, perm=torch.arange(0, 784).long()):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, targets in test_loader:\n",
    "        # send to device\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "        \n",
    "        # metrics\n",
    "        logits = model(data)\n",
    "        test_loss += F.cross_entropy(logits, targets, reduction='sum').item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == targets).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    \n",
    "    print(f\"test loss={test_loss:.4f}, accuracy={accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:29:57.672488Z",
     "start_time": "2024-06-24T12:29:57.669710Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, n_kernel, output_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=n_kernel, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=n_kernel, out_channels=n_kernel, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=n_kernel * 4 * 4, out_features=50),\n",
    "            nn.Linear(50, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:30:07.187952Z",
     "start_time": "2024-06-24T12:29:58.247104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, step=0: train loss=2.3331\n",
      "epoch=0, step=100: train loss=0.3963\n",
      "epoch=0, step=200: train loss=0.2618\n",
      "epoch=0, step=300: train loss=0.5795\n",
      "epoch=0, step=400: train loss=0.1307\n",
      "epoch=0, step=500: train loss=0.1467\n",
      "epoch=0, step=600: train loss=0.3227\n",
      "epoch=0, step=700: train loss=0.3741\n",
      "epoch=0, step=800: train loss=0.1202\n",
      "epoch=0, step=900: train loss=0.1636\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:30:10.084647Z",
     "start_time": "2024-06-24T12:30:08.941534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss=0.1053, accuracy=0.9661\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters=6.422K\n",
      "epoch=0, step=0: train loss=2.3577\n",
      "epoch=0, step=100: train loss=0.3008\n",
      "epoch=0, step=200: train loss=0.4280\n",
      "epoch=0, step=300: train loss=0.2401\n",
      "epoch=0, step=400: train loss=0.1121\n",
      "epoch=0, step=500: train loss=0.0774\n",
      "epoch=0, step=600: train loss=0.1168\n",
      "epoch=0, step=700: train loss=0.1807\n",
      "epoch=0, step=800: train loss=0.2006\n",
      "epoch=0, step=900: train loss=0.0401\n",
      "test loss=0.1053, accuracy=0.9670\n"
     ]
    }
   ],
   "source": [
    "n_kernels = 6\n",
    "convnet = ConvNet(input_size, n_kernels, output_size)\n",
    "convnet.to(device)\n",
    "print(f\"Parameters={sum(p.numel() for p in convnet.parameters())/1e3}K\")\n",
    "train(convnet)\n",
    "test(convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters=6.442K\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, n_hidden),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(n_hidden, output_size) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        return self.layers(x)\n",
    "\n",
    "input_size = 28 * 28  \n",
    "output_size = 10 \n",
    "n_hidden = 8 \n",
    "\n",
    "mlp = MLP(input_size, n_hidden, output_size)\n",
    "mlp.to(device)\n",
    "\n",
    "print(f\"Parameters={sum(p.numel() for p in mlp.parameters())/1e3}K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, step=0: train loss=2.3190\n",
      "epoch=0, step=100: train loss=1.3788\n",
      "epoch=0, step=200: train loss=0.7669\n",
      "epoch=0, step=300: train loss=0.5916\n",
      "epoch=0, step=400: train loss=0.3541\n",
      "epoch=0, step=500: train loss=0.4469\n",
      "epoch=0, step=600: train loss=0.4886\n",
      "epoch=0, step=700: train loss=0.5212\n",
      "epoch=0, step=800: train loss=0.6407\n",
      "epoch=0, step=900: train loss=0.2031\n"
     ]
    }
   ],
   "source": [
    "train(mlp, n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss=0.4426, accuracy=0.8749\n"
     ]
    }
   ],
   "source": [
    "test(mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
